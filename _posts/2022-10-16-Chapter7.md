---
layout: single
title:  "Chapter7. Combining Different Models for Ensemble Learning"
use_math: true
---

## 1. Learning with ensembles

* 앙상블 방법(ensemble methods)의 목표는 서로 다른 분류기를 일반화 성능이 우수한 메타 분류기로 결합하는 것임.
* 예를 들어, 10명의 전문가로부터 예측을 수집했을 때, 앙상블 방법을 사용하면 10명의 전문가의 예측을 결합하여 각 개별 전문가의 예측보다 더 정확하고 강력한 예측을 도출할 수 있음.
* 앙상블에는 몇 가지 다른 접근법이 존재하며, 이 절에서는 앙상블의 작동원리와 좋은 일반화 성능을 내는 이유에 대해 알아봄.

fig 1

* 가장 인기 있는 앙상블 방법은 다수결 투표(plurality voting) 방식임. 
* 위 그림은 10개의 분류기로 구성된 앙상블에 대한 다수결(majority) 및 다수결 투표(plurality voting)의 개념을 보여줌. 여기서 각 고유한 기호(삼각형, 사각형 및 원)는 고유한 클래스 레이블을 나타냄.
* 다수결 이름 그대로 50% 이상의 표를 받은 등급표를 선정하는 방식을 의미함. 

fig 2

* 훈련 데이터 세트를 사용하여 m개의 다른 분류기$(C1, ..., Cm)$를 교육하는 것으로 시작하며 앙상블 방법에 따라, 결정 트리, 지원 벡터 머신, 로지스틱 회귀 분류기 등과 같은
다양한 분류 알고리즘으로 구성될 수 있음. (또는 훈련 데이터 세트의 다른 하위 집합에 맞는 동일한 기본 분류 알고리듬을 사용할 수 있음.)
* 유명한 예는 서로 다른 의사 결정 트리 분류기를 결합한 랜덤 포레스트(random forest) 알고리듬이 있음.
* 위 그림은 다수결 투표를 이용한 일반적인 앙상블 접근법의 개념을 보여줌.
* 과반수 투표나 다수결 투표를 통해 클래스 레이블을 예측하기 위해 개별 분류기의 $C_{j}$의 예측 클래스 레이블을 결합하여 가장 많은 표를 얻은 클래스 레이블 $\hat{y}$을 선택할 수 있음.

$$ \hat{y} = mode\{C_{1}(x),C_{2}(x),\cdots,C_{m}(x) \} $$

* (위 식에서) 통계학에서 mode는 집합에서 가장 빈번한 event 또는 result임.
* 예를 들어, $class1 = –1$  및 $class2 = +1$인 이진 분류 작업에서 다수결 예측은 다음과 같음.

$$ C(x)=sign \[ \sum_{j}^{m} C_{j}(x)\] = \left\{\begin{matrix}
1 & if \sum_{j} C_{j}(x) \geq 0\\ 
-1 & otherwise
\end{matrix}\right. $$ 

* 앙상블 방법이 개별 분류기보다 더 잘 작동할 수 있는 이유를 설명하기 위해 조합론의 몇 가지 개념을 적용함.
* 예를 들어, 이진 분류 작업에 대한 모든 n개의 분류기가 동일한 에러율인 $\varepsilon$를 갖는 분류기가 있으며 분류기가 서로에게 영향을 주지 않는 독립적 관계라고 가정함.
* 위와 같은 가정하에, 단순히 기저 분류기의 앙상블의 오차 확률을 이항 분포의 확률 질량 함수로 표현할 수 있음.

$$ P(y\geq k)=\sum_{k}^{n} \left \langle nk\right \rangle \varepsilon^{k}(1-0.25)^{n-k}=\varepsilon^{ensemble} $$

* 위 식에서, 이항 계수 n개 원소에서 k개를 뽑는 조합임. 이 식은 앙상블이 틀릴 확률을 계산함. 에러율이 0.25인 분류기 11개로 구성된 앙상블 에러율은 0.034의 값을 가짐.
* 보시다시피 모든 가정이 충족될 경우 앙상블의 오차율(0.034)이 각 개별 분류기의 오차율(0.25)보다 훨씬 낮음. 
* 만약 에러율이 0.5인 분류기가 짝수 개의 분류기 n으로 분할하면 오류로 처리됨.
* 일단 이상주의적 앙상블 분류기를 다양한 기본 에러율 범위에 걸쳐 기본 분류기와 비교하기 위해, 파이썬에서 확률 질량 함수를 아래와 같이 구현함. 


```python
>>> from scipy.special import comb
>>> import math
>>> def ensemble_error(n_classifier, error):
... k_start = int(math.ceil(n_classifier / 2.))
... probs = [comb(n_classifier, k) *
... error**k *
... (1-error)**(n_classifier - k)
... for k in range(k_start, n_classifier + 1)]
... return sum(probs)
>>> ensemble_error(n_classifier=11, error=0.25)
0.03432750701904297
```

* angemble_error 함수를 구현한 후, 0.0에서 1.0까지의 다양한 기본 오류 범위에 대한 앙상블 에러율을 계산하여, 앙상블과 기본 오류 사이의 관계를 시각화할 수 있음. 

```python
>>> import numpy as np
>>> import matplotlib.pyplot as plt
>>> error_range = np.arange(0.0, 1.01, 0.01)
>>> ens_errors = [ensemble_error(n_classifier=11, error=error)
... for error in error_range]
>>> plt.plot(error_range, ens_errors,
... label='Ensemble error',
... linewidth=2)
>>> plt.plot(error_range, error_range,
... linestyle='--', label='Base error',
... linewidth=2)
>>> plt.xlabel('Base error')
>>> plt.ylabel('Base/Ensemble error')
>>> plt.legend(loc='upper left')
>>> plt.grid(alpha=0.5)
>>> plt.show()
```

fig 3

* 위 그림의 y축은 기본 오차(점선)과 앙상블 오차(실선)을 나타내며, 이를 통해 기본 분류기가 랜덤 추측보다 더 나은 성능을 발휘하는 한 앙상블의 오차 확률은 항상 개별 분류기의 오차보다 높음.($\varepsilon < 0.5$)

## 2. Combining classifiers via majority vote
* 파이썬에서 다수결 투표를 위한 간단한 앙상블 분류기를 구현

#### * Implementing a simple majority vote classifier

* 특정 데이터 세트에서 개별 분류기의 약점을 균형 있게 조정하는 더 강력한 메타 분류기를 구축하는데 목표
* 보다 정확한 수학 용어로, 가중 다수표를 다음과 같이 쓸 수 있음.

$$ \hat{y} = argmax\sum_{j=1}^{m}w_{j}\chi _{A}(C_{j}(x)=i) $$

* 위 식에서, w는 c라는 분류기 연관된 가중치이며, $\hat{y}$은 앙상블에서 예측한 클래스 레이블, $\chi$는 특성함수를 의미함.
* 가중치 개념을 더 잘 이해하기 위해, 좀 더 구체적인 예를 살펴봄. 세 가지 기본 분류기 $C_{j}(j\in {1,2,3})$의 앙상블이 있고 주어진 예제의 클래스 레이블 $C_{j}(x)\in \{0,1 \}$을 예측하고 싶다고 가정
* 세 가지 중 두 가지 기본 분류기는 클래스 레이블을 0으로 예측하고, 한 가지 $C_{3}$는 해당 예가 1에 속한다고 예측, 각 기본 분류기의 예측에 균등하게 가중치를 부여하면 다수결은 예제가 클래스 0에 속한다고 예측함. 

$$ C_{1}\rightarrow 0, C_{2}\rightarrow 0, C_{3}\rightarrow 1 $$

$$ \hat{y} = mode \{0,0,1\} = 0 $$

* 이제, $C_{3}$에 0.6의 가중치를 할당하고, $C_{1}$과 $C_{2}$에 0.2의 계수를 부여하면, 1의 결과값을 얻음.
* 보다 간단하게, 3×0.2 = 0.6이므로, $C_{3}$에 의한 예측은 $C_{1}$과 $C_{2}$에 의한 예측보다 3배 더 많은 가중치를 가지고 있다고 말할 수 있으며, 이를 다음과 같이 쓸 수 있음.

$$ \hat{y} = mode \{0,0,1,1,1\} = 1 $$

* 가중 다수결의 개념을 파이썬 코드로 변환하기 위해, 빈카운트가 각 클래스 라벨의 발생 횟수를 카운트하는 NumPy의 편리한 argmax 및 bincount 함수를 사용할 수 있음.
* 그런 다음 argmax 함수는 다수 클래스 레이블에 해당하는 가장 높은 카운트의 인덱스 위치를 반환(이것은 클래스 레이블이 0에서 시작한다고 가정함).

```python
to the majority class label (this assumes that class labels start at 0):
>>> import numpy as np
>>> np.argmax(np.bincount([0, 0, 1],
... weights=[0.2, 0.2, 0.6]))
1
```

* 확률로부터 클래스 레이블을 예측하기 위한 다수결의 수정된 버전은 다음과 같이 작성됨.

$$ \hat{y} = argmax\sum_{j=1}^{m} w_{j}p_{ij} $$

* 위 식에서 $p_{ij}$는 클래스 레이블 $i$에 대한 $j$번째 분류기의 확률임. 
* 이전 예제를 계속하기 위해 클래스 레이블 $C_{j}(j\in {1,2,3})$ 및 세 가지 분류기로 구성된 앙상블$C_{j}(x)\in \{0,1 \}$에 이진 분류 문제가 있다고 가정
* 분류자 $C_{j}$가 특정 예제 $x$에 대해 다음과 같은 클래스 멤버쉽 확률을 반환한다고 가정

$$ C_{1}(x)\rightarrow [0.9,0.1], C_{2}(x)\rightarrow [0.8,0.2], C_{3}(x)\rightarrow [0.4,0.6] $$

* 이전과 동일한 가중치(0.2, 0.2, 0.6)를 사용하여 다음과 같이 개별 클래스 확률을 계산할 수 있음. 

$$
p(i_{0}|x)= 0.2\times 0.9 + 0.2\times 0.8 + 0.6\times 0.4 = 0.58
p(i_{1}|x)= 0.2\times 0.1 + 0.2\times 0.2 + 0.6\times 0.6 = 0.42
\hat{y} = argmax[p(i_{0}|x),p(i_{1}|x)] = 0
$$

* 클래스 확률을 기반으로 가중 다수 투표를 구현하기 위해 np.average 및 np.argmax를 사용하여 NumPy를 다시 사용할 수 있음.

```python
>>> ex = np.array([[0.9, 0.1],
... [0.8, 0.2],
... [0.4, 0.6]])
>>> p = np.average(ex, axis=0, weights=[0.2, 0.2, 0.6])
>>> p
array([0.58, 0.42])
>>> np.argmax(p)
0
```

#### * Using the majority voting principle to make predictions
이제 이전 섹션에서 구현한 Majority Vote Classifier를 실행할 때입니다. 하지만 먼저 테스트할 수 있는 데이터 세트를 준비합니다. 
우리는 CSV 파일에서 데이터 세트를 로드하는 기술에 이미 익숙하기 때문에 바로 가기를 사용하여 sickit-learn의 데이터 세트 모듈에서 Iris 데이터 세트를 로드한다. 
또한, 우리는 설명 목적으로 분류 작업을 더 어렵게 만들기 위해 세팔 폭과 꽃잎 길이 두 가지 특징만 선택할 것이다. 다수표 분류기가 다중 클래스 문제에 일반화되어 있지만, 
우리는 아이리스-버시컬러 및 아이리스 버지니카 클래스의 꽃 예만 분류할 것이며, 나중에 ROC AUC를 계산할 것이다. 코드는 다음과 같습니다.

* 이전 섹션에서 구현한 Majority Vote Classifier를 실행함. 이전에 테스트할 수 있는 데이터 세트를 준비함. 
* sickit-learn의 데이터 세트 모듈에서 Iris 데이터 세트를 로드하고 분류 작업을 더 어렵게 만들기 위해 세팔 폭과 꽃잎 길이 두 가지 특징만 선택함.
* 다수표 분류기가 다중 클래스 문제에 일반화되어 있지만 Iris-versicolor 및 Iris-virginica 클래스의 꽃 예만 분류할 것이며, 나중에 ROC AUC를 계산할 것임. 코드는 다음과 같음.

```python
>>> from sklearn import datasets
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.preprocessing import LabelEncoder
>>> iris = datasets.load_iris()
>>> X, y = iris.data[50:, [1, 2]], iris.target[50:]
>>> le = LabelEncoder()
>>> y = le.fit_transform(y)
```

* 다음으로, Iris 예제를 50% 훈련 데이터와 50% 테스트 데이터로 나눔.

```python
>>> X_train, X_test, y_train, y_test =\
... train_test_split(X, y,
... test_size=0.5,
... random_state=1,
... stratify=y)
```

* 훈련 데이터 세트를 사용하여 이제 세 가지 분류자를 교육할 것이다.
    1. 로지스틱 회귀 분석 분류기
    2. 의사 결정 트리 분류기
    3. k-nearest 인접 분류기 

* 그런 다음 앙상블 분류기로 결합하기 전에 교육 데이터 세트에 대한 10배 교차 검증을 통해 각 분류기의 모델 성능을 평가할 것임. 

```python
>>> from sklearn.model_selection import cross_val_score
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.tree import DecisionTreeClassifier
>>> from sklearn.neighbors import KNeighborsClassifier
>>> from sklearn.pipeline import Pipeline
>>> import numpy as np
>>> clf1 = LogisticRegression(penalty='l2',
... C=0.001,
... solver='lbfgs',
... random_state=1)
>>> clf2 = DecisionTreeClassifier(max_depth=1,
... criterion='entropy',
... random_state=0)
>>> clf3 = KNeighborsClassifier(n_neighbors=1,
... p=2,
... metric='minkowski')
>>> pipe1 = Pipeline([['sc', StandardScaler()],
... ['clf', clf1]])
>>> pipe3 = Pipeline([['sc', StandardScaler()],
... ['clf', clf3]])
>>> clf_labels = ['Logistic regression', 'Decision tree', 'KNN']
>>> print('10-fold cross validation:\n')
>>> for clf, label in zip([pipe1, clf2, pipe3], clf_labels):
... scores = cross_val_score(estimator=clf,
... X=X_train,
... y=y_train,
... cv=10,
... scoring='roc_auc')
... print(f'ROC AUC: {scores.mean():.2f} '
... f'(+/- {scores.std():.2f}) [{label}]')
```

* 다음 코드에서 보는 바와 같이, 우리가 받은 출력은 개별 분류기의 예측 성능이 거의 같다는 것을 보여줌.

```python
10-fold cross validation:
ROC AUC: 0.92 (+/- 0.15) [Logistic regression]
ROC AUC: 0.87 (+/- 0.18) [Decision tree]
ROC AUC: 0.85 (+/- 0.13) [KNN]
```

* 파이프라인의 일부로 로지스틱 회귀 분석 및 k-근접 이웃 분류기를 훈련하는 이유는 제3장에서 논의한 바와 같이 로지스틱 회귀 알고리즘과 k-근접 이웃 알고리즘(유클리드 거리 메트릭 사용)이 모두 의사결정 트리와 달리 스케일 불변성이 아니기 때문임.
* Iris 특성은 모두 동일한 척도(cm)로 측정되지만 표준화된 기능으로 작업하는 것은 좋은 습관임.
* 이제 MajorityVoteClassifier에서 다수결 투표를 위한 개별 분류기를 결합

```python
>>> mv_clf = MajorityVoteClassifier(
... classifiers=[pipe1, clf2, pipe3]
... )
>>> clf_labels += ['Majority voting']
>>> all_clf = [pipe1, clf2, pipe3, mv_clf]
>>> for clf, label in zip(all_clf, clf_labels):
... scores = cross_val_score(estimator=clf,
... X=X_train,
... y=y_train,
... cv=10,
... scoring='roc_auc')
... print(f'ROC AUC: {scores.mean():.2f} '
... f'(+/- {scores.std():.2f}) [{label}]')
ROC AUC: 0.92 (+/- 0.15) [Logistic regression]
ROC AUC: 0.87 (+/- 0.18) [Decision tree]
ROC AUC: 0.85 (+/- 0.13) [KNN]
ROC AUC: 0.98 (+/- 0.05) [Majority voting]
```

* 위 코드의 실행 결과를 통해 MajorityVotingClassifier의 성능이 10배 교차 검증 평가에서 개별 분류기에 비해 향상되었음.



## 3. Evaluating and tuning the ensemble classifier

* 이 섹션에선 MajorityVoteClassifier가 보이지 않는 데이터로 잘 일반화되는지 확인하기 위해 테스트 데이터 세트에서 ROC 곡선을 계산
* 테스트 데이터 세트가 모델 선택에 사용되어서는 안됨. 테스트 데이터 세트는 단지 분류기 시스템의 일반화 성능에 편견 없는 추정치를 구하는 것임.

```python
>>> from sklearn.metrics import roc_curve
>>> from sklearn.metrics import auc
>>> colors = ['black', 'orange', 'blue', 'green']
>>> linestyles = [':', '--', '-.', '-']
>>> for clf, label, clr, ls \
... in zip(all_clf, clf_labels, colors, linestyles):
... # assuming the label of the positive class is 1
... y_pred = clf.fit(X_train,
... y_train).predict_proba(X_test)[:, 1]
... fpr, tpr, thresholds = roc_curve(y_true=y_test,
... y_score=y_pred)
... roc_auc = auc(x=fpr, y=tpr)
... plt.plot(fpr, tpr,
... color=clr,
... linestyle=ls,
... label=f'{label} (auc = {roc_auc:.2f})')
>>> plt.legend(loc='lower right')
>>> plt.plot([0, 1], [0, 1],
... linestyle='--',
... color='gray',
... linewidth=2)
>>> plt.xlim([-0.1, 1.1])
>>> plt.ylim([-0.1, 1.1])
>>> plt.grid(alpha=0.5)
>>> plt.xlabel('False positive rate (FPR)')
>>> plt.ylabel('True positive rate (TPR)')
>>> plt.show()
```

fig 4

* 결과에서 볼 수 있듯이 앙상블 분류기는 테스트 데이터 세트에서도 우수한 성능을 발휘합니다(ROC AUC = 0.95).
* 그러나 로지스틱 회귀 분석 분류기가 동일한 데이터 집합에서 유사하게 수행된다는 것을 알 수 있음. 이는 데이터 집합의 크기가 작을 때 분산(데이터 집합을 분할하는 방법의 민감도)이 높기 때문임.

* 모델 피팅에 앞서 훈련 특성을 표준화할 필요는 없지만, 지스틱 회귀 및 k-가장 가까운 이웃 파이프라인은 자동으로 이를 처리하기 때문에, 의사 결정 트리의 결정 영역이 시각적 목적을 위해 동일한 척도에 있도록 훈련 데이터 세트를 표준화함.

```python
>>> sc = StandardScaler()
>>> X_train_std = sc.fit_transform(X_train)
>>> from itertools import product
>>> x_min = X_train_std[:, 0].min() - 1
>>> x_max = X_train_std[:, 0].max() + 1
>>> y_min = X_train_std[:, 1].min() - 1
>>>
>>> y_max = X_train_std[:, 1].max() + 1
>>> xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
... np.arange(y_min, y_max, 0.1))
>>> f, axarr = plt.subplots(nrows=2, ncols=2,
... sharex='col',
... sharey='row',
... figsize=(7, 5))
>>> for idx, clf, tt in zip(product([0, 1], [0, 1]),
... all_clf, clf_labels):
... clf.fit(X_train_std, y_train)
... Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
... Z = Z.reshape(xx.shape)
... axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.3)
... axarr[idx[0], idx[1]].scatter(X_train_std[y_train==0, 0],
... X_train_std[y_train==0, 1],
... c='blue',
... marker='^',
... s=50)
... axarr[idx[0], idx[1]].scatter(X_train_std[y_train==1, 0],
... X_train_std[y_train==1, 1],
... c='green',
... marker='o',
... s=50)
... axarr[idx[0], idx[1]].set_title(tt)
>>> plt.text(-3.5, -5.,
... s='Sepal width [standardized]',
... ha='center', va='center', fontsize=12)
>>> plt.text(-12.5, 4.5,
... s='Petal length [standardized]',
... ha='center', va='center',
... fontsize=12, rotation=90)
>>> plt.show()
```



흥미롭게도, 또한 예상대로 앙상블 분류기의 결정 영역은 개별 분류기의 결정 영역의 혼합인 것처럼 보인다. 
언뜻 보면, 다수결 결정 경계는 결정 트리 그루터기의 결정과 매우 흡사하며, 이는 세팔 폭 1 1에 대한 y축과 직교한다.
그러나 k-근접 이웃 분류기가 혼합된 비선형성도 확인할 수 있습니다.

fig 5

앙상블 분류를 위해 개별 분류기의 매개 변수를 조정하기 전에 get_params 메서드를 호출하여 
GridSearchCV 개체 내의 개별 매개 변수에 액세스하는 방법에 대한 기본 아이디어를 얻습니다.



