
---
layout: single
title:  "Chapter7. Combining Different Models for Ensemble Learning"
use_math: true
---

## 1. Learning with ensembles

* <mark style='background-color: #fff5b1'>앙상블 방법(ensemble methods)</mark> 의 목표는 **서로 다른 분류기를 각각의 개별로서의 단독 분류기보다 성능이 우수한 하나의 메타 분류기로 결합하는 것임.**
* 예를 들어, 10명의 전문가로부터 예측을 수집했을 때, 앙상블 방법을 사용하면 10명의 전문가의 예측을 결합하여 각 개별 전문가의 예측보다 더 정확하고 강력한 예측을 도출할 수 있음.
* 앙상블에는 몇 가지 다른 접근법이 존재하며, 이 절에서는 앙상블의 작동원리와 앙상블이 좋은 성능을 가지는 이유에 대해 알아봄.

![1](https://user-images.githubusercontent.com/113302607/196036804-692b08c3-42ca-4355-ae6b-753ef2eee333.png)
<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.1. The different voting concepts
</figcaption>

* 가장 인기 있는 앙상블 방법은 **과반수 투표(majority voting)** 방식임. 이는 이름에서 알 수 있듯 분류기의 **과반수가 예측한 클래스 레이블을 선택**하는 방법임.
* 과반수 투표는 이중 클래스 분류에 해당되지만, 다중 클래스 문제에서의 일반화도 가능함. 이를 **다수결 투표(plurality voting)** 라고 하며 최빈값을 선택하는 방법임. 
* 위 그림은 10개의 분류기로 구성된 앙상블에 대한 **과반수 투표(majority voting)** 및 **다수결 투표(plurality voting)** 의 개념을 보여줌. 여기서 각 고유한 기호(삼각형, 사각형 및 원)는 고유한 클래스 레이블을 나타냄.

![2](https://user-images.githubusercontent.com/113302607/196036808-cffb8eab-bacd-4751-a7d6-f2f5813b6c06.png)
<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.2. A general ensemble approach
</figcaption>

* 훈련 데이터 세트를 사용하여 $m$개의 다른 분류기$(C1, ..., Cm)$를 훈련하는 것으로 시작하며 이를 C라고 명명함. 
* 앙상블 방법에 따라, 결정 트리, 지원 벡터 머신, 로지스틱 회귀 분류기 등과 같은 다양한 알고리즘을 사용하여 구축 또는 훈련 데이터 세트의 부분 집합을 달리하여 훈련할 수 있음.
* 유명한 예는 서로 다른 의사 결정 트리 분류기를 결합한 랜덤 포레스트(random forest) 알고리듬이 있음.
* 위 그림은 다수결 투표를 이용한 일반적인 앙상블 접근법의 개념을 보여줌.
* 과반수 투표나 다수결 투표를 통해 클래스 레이블을 예측하기 위해 개별 분류기의 $C_{j}$의 예측 클래스 레이블을 결합하여 가장 많은 표를 얻은 클래스 레이블 $\hat{y}$을 선택할 수 있음.

$\hat{y} = mode\{C_{1}(x),C_{2}(x),\cdots,C_{m}(x)\}$

* 위 식에서와 같이 과반수 투표나 다수결 투표로 예측을 하면 개별 분류기의 예측 레이블을 모아 가장 많은 표를 받은 레이블 \hat{y}을 선택함.
* (위 식에서) 통계학에서 mode는 집합에서 가장 빈번한 event 또는 result를 의미함.
* 예를 들어, $class1 = –1$  및 $class2 = +1$인 이진 분류 작업에서 과반수 투표 예측은 다음과 같음.

$$ C(x)=sign \[ \sum_{j}^{m} C_{j}(x)\] = \left\{\begin{matrix}
1 & if \sum_{j} C_{j}(x) \geq 0\\ 
-1 & otherwise
\end{matrix}\right. $$ 

* **앙상블 방법(하나의 메타 분류기)이 개별 분류기보다 더 잘 작동할 수 있는 이유**를 설명하기 위해 조합론의 몇 가지 개념을 적용함.
* 예를 들어, 이진 분류 작업에 대한 동일한 에러율 $\varepsilon$를 가지는 $n$개의 분류기가 있으며, $n$개의 분류기가 서로에게 영향을 주지 않는 독립적 관계라고 가정함.
* 위와 같은 가정하에, 단순히 기저 분류기의 앙상블의 오차 확률을 이항 분포의 확률 질량 함수로 표현할 수 있음.

$P(y\geq k)=\sum_{k}^{n} \left \langle nk\right \rangle \varepsilon^{k}(1-0.25)^{n-k}=\varepsilon^{ensemble}$

* 위 식에서, 이항 계수로 $n$개의 원소에서 $k$개를 뽑는 조합을 의미함. 이 식은 앙상블이 틀릴 확률을 계산함. 
* 에러율이 $0.25$인 분류기 $11$개로 구성된 앙상블 에러율은 $0.034$의 값을 가짐.
* 위와 같이 계산이 됐을 때, 각 개별 분류기의 오차율인 $0.25$보다 앙상블의 오차율이 확연히 낮은 것을 확인할 수 있음.
* 만약, 에러율이 $0.5$인 분류기가 짝수라 예측이 반반으로 분할되면 에러로 취급됨.
* 일단 이상주의적 앙상블 분류기를 다양한 기본 에러율 범위에 걸쳐 기본 분류기와 비교하기 위해, 파이썬에서 확률 질량 함수를 아래와 같이 구현함. 

```python
>>> from scipy.special import comb
>>> import math
>>> def ensemble_error(n_classifier, error):
... k_start = int(math.ceil(n_classifier / 2.))
... probs = [comb(n_classifier, k) *
... error**k *
... (1-error)**(n_classifier - k)
... for k in range(k_start, n_classifier + 1)]
... return sum(probs)
>>> ensemble_error(n_classifier=11, error=0.25)
0.03432750701904297
```
