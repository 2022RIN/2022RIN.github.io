---
layout: single
title:  "Chapter6. Learning Best Practices for Model Evaluation and Hyperparameter Tuning"
use_math: true
---
## 1. Streamlining workflows with pipelines 

* 이 섹션에서는 sickit-learn의 Pipeline 클래스에 대해 배움. 

#### * The main steps in principal component analysis

* 위스콘신 유방암 데이터 세트는 569개의 악성 및 양성 종양 샘플이 포함되어있음. 두 열은 샘플의 진단(M = 악성, B = 양성)의 고유한 ID 번호를 저장하며, 3~32 열에는 세포 핵의 이미지에서 계산된 30개의 실제 값 특징이 포함됨.

1. 먼저 UCI 웹 사이트에서 판다를 사용하여 데이터 세트를 읽어옴.

```python
>> import pandas as pd
>>> df = pd.read_csv('https://archive.ics.uci.edu/ml/'
... 'machine-learning-databases'
... '/breast-cancer-wisconsin/wdbc.data',
... header=None)
```

2. 다음으로 30개의 특성을 NumPy 배열 X에 할당하고, LabelEncoder 객체를 사용하여 클래스 레이블을 원래 문자열 표현('M' 및 'B')에서 정수로 변환함.

```python
>>> from sklearn.preprocessing import LabelEncoder
>>> X = df.loc[:, 2:].values
>>> y = df.loc[:, 1].values
>>> le = LabelEncoder()
>>> y = le.fit_transform(y)
>>> le.classes_
array(['B', 'M'], dtype=object)
```

3. 배열에서 클래스 레이블(진단)을 인코딩한 후 y, 악성 종양은 클래스 1로, 양성 종양은 클래스 0으로 각각 표시되며, 두 개의 더미 클래스 레이블에 장착된 LabelEncoder의 변환 방법을 호출하여 이 매핑을 다시 확인할 수 있음.

```python
>> le.transform(['M', 'B'])
array([1, 0])
```

4. 다음 섹션에서 첫 번째 모델 파이프라인을 구축하기 전에 데이터 세트를 별도의 교육 데이터 세트(80%)와 별도의 테스트 데이터 세트(20%)로 나눔.

```python
>>> from sklearn.model_selection import train_test_split
>>> X_train, X_test, y_train, y_test = \
... train_test_split(X, y,
... test_size=0.20,
... stratify=y,
... random_state=1)
```

#### * Combining transformers and estimators in a pipeline
* 이전 챕터들에서 많은 학습 알고리즘에게서 최적의 성능을 끌어내기 위해 입력 특성은 동일한 규모를 가져야함.이에따라 위스콘신 유방암 데이터 세트도 특성 표준화가 필요함. 
* 5장에서 소개한 PCA를 통해 30차원의 데이터를 2차원의 부분공간으로 압축한다고 가정함. 

* 훈련 및 테스트 데이터 세트에 대한 학습 및 데이터 변환 단계를 별도로 거치지 않고 StandardScaler, PCA 및 LogisticRegression 개체를 Pipeline에 연결할 수 있음. 

```python
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.decomposition import PCA
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.pipeline import make_pipeline
>>> pipe_lr = make_pipeline(StandardScaler(),
... PCA(n_components=2),
... LogisticRegression())
>>> pipe_lr.fit(X_train, y_train)
>>> y_pred = pipe_lr.predict(X_test)
>>> test_acc = pipe_lr.score(X_test, y_test)
>>> print(f'Test accuracy: {test_acc:.3f}')
Test accuracy: 0.956
```
* **위 코드 분석**
* **make_pipeline**: 임의의 수의 사이킷런 변환기(fit 및 transform메서드 입력으로 지원하는 객체)를 취한 다음, 사이킷런 추정기(fit 및 predict메서드을 입력으로 구현하는 객체)를 연결시켜줌. 
* 위 코드에서는 두 개의 변환기 **StandardScaler** 및 **PCA**와 **LogisticRegression** 추정기를 **make_pipeline**의 입력으로 제공하였으며, 이 함수는 사이킷런의 **Pipeline** 클래스 객체를 생성하여 반환해줌. 
* 사이킷런의 **Pipeline** 클래스를 변압기와 추정기 주변의 메타 추정기(meta-estimator) 또는 랩로 생각할 수 있음.
* **Pipeline** 의 fit 메서드를 호출하면 **StandardScaler** 의 fit 및 transform메서드를 호출함. 이는 다음 **PCA**에 전달되며 **PCA** 의 fit 및 transform메서드를 호출하며 이는 추정기에 데이터가 전달됨.
* 
* 위 코드에서 pipe_lr 파이프라인에 fit 메서드를 실행했을 때, StandardScaler는 훈련 데이터에 대해 fit 및 transform 호출을 처음 수행하였음. 이렇게 변환된 훈련 데이터는 다음 개체인 PCA로 전달되었음. 
* 이제 **LogisticRegression** 은 이를 토대로 학습을 진행함. **여기서, 파이프라인 중간 단계 개수는 제한이 없지만 마지막 파이프라인 요소는 추정기가 되어야함.**
* 파이프라인의 마지막 단계가 추정기인 경우, 파이프라인도 **predict** 메서드를 구현함. **predict** 메서드 호출에 데이터 세트를 제공하는 경우 데이터는 transform메서드 호출을 통해 중간단계를 통과하고, 마지막 단계에서 추정기 개체가 변환된 데이터에 대한 **predict** 을 반환함. 

fig1

## 2. Using k-fold cross-validation to assess model performance


#### * The holdout method

* 기계 학습 모델의 일반화 성능을 추정하기 위한 고전적이고 대중적인 접근 방식은 홀드아웃 방법이 있음. 
* 홀드아웃 방법을 사용하여 초기 데이터 세트를 별도의 훈련 및 테스트 데이터 세트로 분할함. 전자는 모델 훈련에 사용되며 후자는 일반화 성능을 추정하는데 사용됨. 
* 일반적인 기계 학습 응용 프로그램에서 우리는 처음보는 데이터에 대한 예측 성능을 더욱 향상시키기 위해 하이퍼파라미터(hyperparameters)를 튜닝함. 이 프로세스를 **모델 선택(model selection)** 이라함. 
* 그러나 모델 선택 중에 동일한 테스트 데이터 세트를 반복적으로 재사용하면 훈련 데이터의 일부가 되어 모델이 overfit될 가능성이 높아짐.
* 모델 선택에 홀드아웃 방법을 사용하는 더 나은 방법은 데이터를 훈련 데이터 세트, 검증 데이터(validation dataset) 세트 및 테스트 데이터 세트의 세 부분으로 분리하는 방법임.
* 훈련 데이터 세트는 다양한 모델에 적합하도록 사용되며, 검증 데이터 세트의 성능은 모델 선택에 사용됨.
* 



교육 데이터 세트는 다양한 모델에 적합하도록 사용되며, 검증 데이터 세트의 성능은 모델 선택에 사용됩니다. 교육 및 모델 선택 단계에서 모델이 이전에 보지 못한 테스트 데이터 세트를 사용하는 이점은 새로운 데이터로 일반화하는 능력에 대한 편견이 덜한 추정치를 얻을 수 있다는 것입니다. 그림 6.2는 서로 다른 초 매개 변수 값을 사용하여 교육 후 모델의 성능을 반복적으로 평가하기 위해 검증 데이터 세트를 사용하는 홀드아웃 교차 검증의 개념을 보여줍니다. 하이얼 매개 변수 값의 조정에 만족하면 테스트 데이터 세트에서 모델의 일반화 성능을 추정합니다.
