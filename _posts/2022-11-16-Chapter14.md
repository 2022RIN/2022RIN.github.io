---
layout: single
title:  "Chapter14. Classifying Images with Deep Convolutional Neural Networkss"
use_math: true
---

#### Topic
* 이 장에서는 이미지 분류를 위한 **컨벌루션 신경망(convolutional neural networks, CNNs)** 에 대한 내용임.
* 상향식 접근법(bottom-up-approach)을 사용하여 CNN의 기본 구성 요소에 대해 논의하는 것을 시작으로 CNN의 아키텍처에 대해 더 자세히 알아보고 파이토치에서 CNN을 구현하는 방법에 대해 알아봄. 
* 다음과 같은 항목을 다룸.
* 1) 1차원 및 2차원에서의 컨벌루션 연산
* 2) CNN 아키텍처의 구성 요소
* 3) 파이토치에서 심층 CNN 구현 
* 4) 일반화 성능 향상을 위한 데이터 확대 기법(data augmentation techiques)
* 5) 웃고있는 여부를 인식하기 위한 CNN 얼굴 분류기 구현 

## 1. Understanding CNNs and feature hierarchies: CNN 및 기능 계층 이해

* **중요한(관련) 특징(salient (relevant) features)** 을 성공적으로 추출하는 것은 모든 머신 러닝 알고리즘의 핵심 성능임. 전통적인 머신러닝 모델은 도메인 전문가가 제공하거나 계산 특징 추출 기술은 기반으로하는 입력 특징에 의존함. 이러한 이유로 CNN 레이어를 **특성 추출기**로 간주하는 것이 일반적임.
* 초기 레이어(입력 레이어 바로 뒤의 레이어)는 원시 데이터에서 낮은 수준의 특성을 추출하고, 후기 레이어(MLP처럼 완전 연결된 레이어)는 이러한 특성을 사용하여 연속적인 목표 값 또는 클래스 레이블을 예측함.
* 특성 유형의 다층 NN, 특히 심층 CNN은 **낮은 수준의 기능을 계층별 방식으로 결합하여 높은 수준의 특성을 형성함으로써 소위 특성 계층(feature hierarchy)을 구성함.** 
* 예를 들어, 이미지를 다루는 경우에 가장자리와 블롭과 같은 낮은 수준의 특성가 이전 레이어에서 추출되고, 이는 결합되어 높은 수준의 특성을 형성함. 
* 이와 같은 높은 수준의 특성은 건물이나 동물 같은 물체의 윤곽과 같은 복잡한 모양을 형성할 수 있음.


<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.1. Creating feature maps from an image (photo by Alexander Dummer on Unsplash)
</figcaption>

* 위 그림처럼 CNN은 입력 이미지에서 특성 맵을 계산함. 여기서 각 요소는 입력 이미지 픽셀의 로컬 패치에서 나옴.
* 이러한 픽셀들의 로컬 패치를 로컬 수용 필드(local receptive field)라함. CNN은 일반적으로 이미지 관련 작업에서 잘 수행되며 이는 다음과 같은 두 가지 아이디어 때문임.
* **희소 연결(sparse connectivity)**: 특성 맵의 단일 요소는 작은 픽셀 패치에만 연결된다(MLP의 경우와 같이 전체 입력 이미지에 연결하는 것과는 매우 다르다).
* **매개 변수 공유(parameter sharing)**: 입력 이미지의 다른 패치에 동일한 가중치가 사용됨.
* 위 두 아이디어의 결과로, 완전히 연결된 기존의 MLP를 컨볼루션 레이어로 대체하면 네트워크의 가중치(파라미터) 수가 상당히 감소하며, 두드러진 특성을 포착하는 능력이 향상됨.
* 이미지 데이터의 맥락에서, 가까운 거리의 픽셀들은 일반적으로 서로 멀리 떨어져 있는 픽셀들보다 서로에게 더 관련이 있다고 가정하는 것이 타당함.
* 일반적으로 **CNN은 끝에 하나 이상의 완전히 연결된 계층이 이어지는 여러 컨볼루션 및 하위 샘플링 계층으로 구성**됨. 완전히 연결된 층은 기본적으로 MLP이며, 여기서 모든 입력 단위 i는 가중치 $w_{ij}$로 모든 출력 단위 j에 연결됨.
* 일반적으로 **풀링 레이어(pooling layers)** 로 알려진 하위 샘플링 레이어에는 학습 가능한 매개 변수가 없음. 예를 들어 풀링 레이어에는 가중치 또는 편향 단위가 없지만 컨볼루션 레이어와 완전히 연결된 레이어 모두 훈련 중에 최적화된 가중치와 편향이 존재함.

## 2. Understanding CNNs and feature hierarchies: 이산 컨볼루션 수행

* 이산 컨볼루션(discrete convolution (or simply convolution))은 CNN의 기본 연산으로 어떻게 작동하는지 이해하는 것이 중요함. 

#### Discrete convolutions in one dimension: 1차원에서의 이산 컨볼루션

* 몇 가지 기본적 정의와 표기법을 살펴봄. $y=xw$ 두 벡터, x와 w에 대한 이산 컨볼루션은 벡터 x가 입력(또는 신호)이고, w는 필터 또는 커널임.
먼저 사용할 몇 가지 기본적인 정의와 표기법부터 살펴보겠습니다. 두 벡터, 즉 x와 w에 대한 이산 컨볼루션은 벡터 x가 우리의 입력(때로는 신호라고 불림)이고 w는 필터 또는 커널이라고 한다. 이산 컨볼루션은 수학적으로 다음과 같이 정의된다.

(1)

* 대괄호 [ ]는 벡터 요소의 인덱싱을 나타내는 데 사용되며 인덱스 i는 출력 벡터 y의 각 요소를 통과함.
* 앞의 공식에서 명확히 알아야할 것: $-\infty$ 에서 $\infty$와 x에 대한 음수 인덱스
* 합이 $-\infty$ 에서 $\infty$ 까지의 인덱스를 통과하는 것은 주로 기계 학습 애플리케이션에서 항상 유한한 특성 벡터를 다루기 때문임. 이에 따라 앞의 공식에 나타난 덧셈을 정확히 계산하기 위해 x와 w는 0으로 채워졌다고 가정함. 이를통해 출력 벡터 y가 무한한 크기를 가지며 0을 많이 포함함. x는 유한한 수의 0으로만 패딩이 됨. 

* 이와 같은 프로세스를 제로 패딩(zero-padding)또는 심플 패딩(simply padding)이라함. 
* 각 면에 패딩된 0의 수는 p로 표시되며 1차원 벡터 z의 패딩 예시는 아래와 같음. 

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.2. An example of padding
</figcaption>

* 원래 입력 x와 필터 w가 각각 n개와 m개의 원소를 가지고 있다고 가정함. 패딩 벡터 $x^{p}$는 n+2p의 크기를 가짐. 이산 컨볼루션을 계산하기 위한 실제 공식은 다음과 같이 변경됨.  

(2)

* 무한 지수 문제 해결 후 두 번째 문제는 x를 $i+m-k$로 인덱싱 하는 것임. 여기서 주목해야 할 중요점은 이 합계에서 x와 w가 서로 다른 방향으로 지수화 되었다는 것임. 
* 하나의 지수가 역방향으로 가는 합을 계산하는 것은 두 지수 중 하나인 x 또는 w가 패딩된 후에 그것들 중 하나를 뒤집은 후 전진 방향으로 합을 계산하는 것과 같음.
* 위와 같이 필터 w를 뒤집어 회전된 필터 $w^{r}$을 구한다고 가정, 그 다음 점적수(dot product) $x[i:i+m].w^{r}$를 구함. 여기서 $x[i:i+m]$는 크기가 m인 x의 패치임. 해당 작업은 슬라이딩 윈도우 방식처럼 반복되어 모든 출력 요소를 가져옴. 

* 다음 그림은 $x=[3 2 1 7 1 2 5 4]$ 및 $w=[\frac{1}{2} \frac{3}{4} 1 \frac{1}{4}]$의 예를 제공하여 처음 3개의 출력 요소가 계산되도록함. 

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.3. The steps for computing a discrete convolution
</figcaption>

* 앞의 예제에서 패딩 크기가 0(p = 0)임을 알 수 있음.
* 회전된 필터 $w^{r}$은 이동할 때마다 두 개의 셀에 의해 이동되며 이 변화는 컨볼루션의 또 다른 초 매개변수인 보폭임. 이 예에서 스트라이드(stride)는 s = 2임. 스트라이드는 입력 벡터의 크기보다 작은 양수여야함.

#### Padding inputs to control the size of the output feature maps: 출력 피쳐 맵의 크기를 제어하는 입력 패딩

* 지금까지, 유한 크기의 출력 벡터를 계산하기 위해 컨볼루션에서 제로 패딩만을 사용하였음. 기술적으로 패딩은 어떤 $p \geq 0$에도 적용이 가능하며 $p$의 선택에 따라 경계 셀은 x의 중간에 위치한 셀과 다르게 취급될 수 있음.
* n=5, m=3인 예에서, $p=0, x[0]$는 하나의 출력요소(예: $y[0]$)를 계산하는 데만 사용되는 반면 $x[1]$은 두 개의 출력 요소 (예: $y[0]$ 및 $y[1]$)를 계산하는 데 사용됨.
* 따라서 x의 요소에 대한 이 다른 처리는 대부분의 계산에서 나타났기 때문에 중간 요소인 x[2]에 인위적으로 더 중점을 둘 수 있다는 것을 알 수 있음.
* p = 2를 선택하면 이 문제를 피할 수 있으며, 이 경우 x의 각 요소는 y의 세 가지 요소를 계산하는 데 포함
* 또한 출력 y의 크기는 우리가 사용하는 패딩 전략의 선택에 따라 달라짐. 실제로 일반적으로 사용되는 패딩에는 풀, 동일, 유효의 세 가지 모드가 있음. 
* 풀 모드에서 패딩 매개변수 $p$는 $p = m – 1$로 설정되며 풀 패딩은 출력의 치수를 증가시킴. 따라서 CNN 아키텍처에는 거의 사용되지 않음. 이 경우 입력 크기 및 출력 크기가 동일해야 하는 요구 사항과 함께 패딩 파라미터 p가 필터 크기에 따라 계산됨.
* 마지막으로, 유효 모드에서 컨볼루션을 계산하는 것은 p = 0 (패딩 없음)인 경우를 의미함.
* 커널 크가 3X3이고 스트라이트가 1인 간단한 5X5 픽셀 입력을 위한 세 가지 다른 패딩 모드를 보여줌.

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.4. The three modes of padding
</figcaption>

* CNN에서 가장 일반적으로 사용되는 패딩 모드는 동일한 패딩임. 다른 패딩 모드에 비해 장점 중 하나는 동일한 패딩이 벡터의 크기(또는 컴퓨터 비전에서 이미지 관련 작업을 할 때 입력 이미지의 높이와 너비)를 보존하여 네트워크 아키텍처를 보다 편리하게 설계할 수 있다는 것임.


#### Determining the size of the convolution output: 컨볼루션 출력의 크기 결정

* 컨볼루션의 출력 크기는 입력 벡터를 따라 필터 w를 이동하는 총 횟수에 의해 결정됨. 력 벡터의 크기가 n이고 필터의 크기가 m인 경우 패딩 p와 스트라이드를 사용하여 $y=xw$ 크기는 다음과 같이 결정됨. 

(3)

* 1차원에서 컨볼루션을 계산하는 방법을 배우기 위해 다음 코드 블록에 순진한 구현을 보여주고, 그 결과를 numpy.convolve 함수와 비교함. 코드는 다음과 같음. 

```python
>>> import numpy as np
>>> def conv1d(x, w, p=0, s=1):
... w_rot = np.array(w[::-1])
... x_padded = np.array(x)
... if p > 0:
... zero_pad = np.zeros(shape=p)
... x_padded = np.concatenate([
... zero_pad, x_padded, zero_pad
... ])
... res = []
... for i in range(0, int((len(x_padded) - len(w_rot))) + 1, s):
... res.append(np.sum(x_padded[i:i+w_rot.shape[0]] * w_rot))
... return np.array(res)
>>> ## Testing:
>>> x = [1, 3, 2, 4, 5, 6, 1, 3]
>>> w = [1, 0, 3, 1, 2]
>>> print('Conv1d Implementation:',
... conv1d(x, w, p=2, s=1))
Conv1d Implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]
>>> print('NumPy Results:',
... np.convolve(x, w, mode='same'))
NumPy Results: [ 5 14 16 26 24 34 19 22]
```

#### Performing a discrete convolution in 2D: 2D에서 이산 컨볼루션 수행

* 이번 섹션에서는 이전 섹션에서 배운 개념을 2D로 확장함. 행렬 $X_{n1xn2}$ $W_{m_{1}Xm_{2}}$와 같은 2차원 입력을 다룰 때,(여기서, $m_{1} \leq  n_{1}$ 그리고 $m_{2} \leq n_{2}$는 X와 W사이의 2차원 컨볼루션 결과임) 이것은 수학적으로 다음과 같이 정의됨. 

* 치수 중 하나를 생략할 경우 남은 공식은 이전에 1D로 컨볼루션을 계산할 때 사용한 공식과 동일함.
* 실제로, 제로 패딩, 필터 매트릭스의 회전, 보폭의 사용과 같은 앞서 언급한 모든 기술들은 두 차원으로 독립적으로 확장된다는 전제하에 2D 컨볼루션에도 적용가능함.
* 아래 그림은 크기가 3x3인 커널을 사용하여 크기가 8x8인 입력 행렬의 2D 컨볼루션을 보여주며 입력 행렬은 p = 1인 0으로 패딩됨. 결과적으로 2D 컨볼루션의 출력은 8x8 크기가 됨.

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.5. The output of a 2D convolution
</figcaption>

## 3. Subsampling layers: 하위 샘플링 도면층

* 서브샘플링은 CNN에서 일반적으로 최대 풀링(max-pooling)과 평균 풀링(평균 풀링이라고도 함)(mean-pooling (also known as average-pooling))이라는 두 가지 형태의 풀링 작업에 적용됨. 
* 풀링 레이어는 보통 $P_{n1xn2}×θ2$로 표시되며, 여기서 첨자는 최대 또는 평균 연산이 수행되는 근방의 크기(각 차원의 인접 픽셀 수)를 결정되며 그러한 이웃을 풀링 크기라고 부름. 
* 동작은 아래 그림과 같음. 여기서 최대 풀링은 픽셀들의 이웃으로부터 최대값을 취하고 평균 풀링은 그들의 평균을 계산함. 

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.6. An example of max-pooling and mean-pooling
</figcaption>

#### 풀링의 두 가지 이점은 다음과 같음. 

* 풀링(최대 풀링)은 로컬 불변성을 도입함. 이는 지역 이웃의 작은 변화가 최대 풀링의 결과를 바꾸지 않는다는 것을 의미함. 따라서 입력 데이터에서 노이즈에 더 강한 기능을 생성하는 데 도움이 됨. X1과 X2라는 두 개의 서로 다른 입력 행렬의 최대 풀링 결과가 동일하다는 것을 보여주는 다음 예는 아래와 같음. 

(5)

* 풀링은 형상의 크기를 감소시켜 계산 효율성을 높임. 또한, 형상의 수를 줄이면 과적합의 정도도 감소할 수 있음.

## 4. Putting everything together – implementing a CNN: 모든 것을 통합 – CNN 구현


#### Working with multiple input or color channels

* 컨볼루션 레이어에 대한 입력은 치수가 $N_{1}xN_{2}$인 하나 이상의 2D 어레이 또는 매트릭스(예를 들어, 픽셀 단위의 이미지 높이 및 너비)를 포함할 수 있음.($N_{1}xN_{2}$ 행렬)
* 이미지가 색상으로 표시되고 RGB 색상 모드를 사용하는 경우 Cin = 3(RGB의 빨간색, 녹색 및 파란색 색상 채널의 경우). 그러나 이미지가 그레이스케일인 경우에는 그레이스케일 픽셀이 있는 채널이 하나뿐이므로 Cin = 1이 됨.
* 이제 입력 데이터의 구조에 익숙해지셨으니, 다음 질문은 이전 섹션에서 논의했던 컨볼루션 작업에서 어떻게 여러 입력 채널을 통합할 수 있는가 하는 것임. 우리는 각 채널에 대한 컨볼루션 연산을 개별적으로 수행한 다음 매트릭스 합계를 사용하여 결과를 함께 추가함. 각 채널 (c)와 연관된 컨볼루션은 W[:, :, c]로서 자체 커널 행렬을 갖음.

(6)


* 최종 결과인 A는 특성 지도임. 일반적으로 CNN의 컨볼루션 레이어는 하나 이상의 피처 맵을 갖음. 다중 형상 맵을 사용하면 커널 텐서는 4차원이 됨: $너비×높이×$C_{in}$×$C_{out}$$. 여기서 너비×높이는 커널 크기, Cin은 입력 채널 수, Cout은 출력 피쳐 맵 수를 나타냄. 이제 앞의 공식에 출력 피쳐 맵의 수를 포함하여 다음과 같이 업데이트함.

(7)


* 아래그림은 컨볼루션 레이어 다음으로 풀링 레이어를 보여줌. 이 예에서는 세 개의 입력 채널이 있음. 커널 텐서는 4차원임. 각 커널 매트릭스는 m1xm2로 표시되며, 각 입력 채널마다 하나씩 세 개가 있음. 또한, 5개의 출력 기능 맵을 설명하는 5개의 커널이 있음. 마지막으로, 피쳐 맵을 서브샘플링하기 위한 풀링 레이어가 있음.


<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.7. Implementing a CNNn
</figcaption>

#### Regularizing an NN with L2 regularization and dropout

* (PyTorch에서 선형)에서 특정 레이어의 L2 패널티를 다음과 같이 PyTorch의 손실 함수에 추가할 수 있음.

```python
>>> import torch.nn as nn
>>> loss_func = nn.BCELoss()
>>> loss = loss_func(torch.tensor([0.9]), torch.tensor([1.0]))
>>> l2_lambda = 0.001
>>> conv_layer = nn.Conv2d(in_channels=3,
... out_channels=5,
... kernel_size=5)
>>> l2_penalty = l2_lambda * sum(
... [(p**2).sum() for p in conv_layer.parameters()]
... )
>>> loss_with_penalty = loss + l2_penalty
>>> linear_layer = nn.Linear(10, 16)
>>> l2_penalty = l2_lambda * sum(
... [(p**2).sum() for p in linear_layer.parameters()]
... )
>>> loss_with_penalty = loss + l2_penalty
```


* 근 몇 년 동안, **드롭아웃**은 과적합을 피하기 위해 (깊은) NN을 정규화하는 인기 있는 기술로 등장하여 일반화 성능을 향상시켰음.(신경망 과적합을 방지하는 간단한 방법임)
* **드롭아웃**은 일반적으로 상위 계층의 숨겨진 단위에 적용되며 다음과 같이 작동: NN의 훈련 단계 동안 숨겨진 단위의 일부는 확률 pdrop(또는 확률 pkeep = 1 – pdrop 유지)으로 모든 반복에서 무작위로 드롭. 이 탈락 확률은 사용자에 의해 결정되며, 앞서 Nitish Srivastava 등이 2014년에 발표한 논문에서 논의한 바와 같이 공통 선택은 p = 0.5. 입력 뉴런의 특정 부분을 떨어뜨릴 때, 나머지 뉴런과 관련된 가중치는 누락된(떨어짐) 뉴런을 설명하기 위해 재조정됨. 이 무작위 드롭아웃의 효과는 네트워크가 데이터의 중복 표현을 학습하도록 강제하는 것임. 따라서 네트워크는 훈련 중 언제든지 꺼질 수 있으므로 숨겨진 장치 세트의 활성화에 의존할 수 없으며 데이터에서 더 일반적이고 강력한 패턴을 학습해야함.

* 드롭아웃 탈락은 과적합을 효과적으로 방지할 수 있음. 아래 그림은 훈련 단계 동안 뉴런의 절반이 무작위로 비활성화되는 확률 p = 0.5의 중퇴를 적용하는 예를 보여줌(훈련의 각 전진 패스에서 무작위 단위가 선택). 그러나, 예측하는 동안, 모든 뉴런은 다음 층의 사전 활성화를 계산하는 데 기여함.


<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.8. Applying dropout during the training phase
</figcaption>

#### Loss functions for classification

* ReLU와 같은 이러한 활성화 기능 중 일부는 주로 NN의 중간(숨겨진) 레이어에서 사용되어 모델에 비선형성을 추가함. 그러나 sigmoid(이진법의 경우)와 softmax(다중 클래스의 경우)와 같은 다른 것들은 마지막 (출력) 계층에 추가되어 모델의 출력으로 클래스 멤버쉽 확률이 생성됨. 만약 sigmoid 또는 softmax 활성화가 출력 계층에 포함되지 않는다면, 모델은 클래스 멤버쉽 확률 대신 로짓을 계산할 것임. 여기서 분류 문제에 초점을 맞춰 문제 유형(이진 대 다중 클래스)과 출력 유형(로짓 대 확률)에 따라 모델을 훈련하기 위해 적절한 손실 함수를 선택해야함. **이진 교차 엔트로피(Binary cross-entropy)** 는 (단일 출력 단위를 갖는) 이진 분류에 대한 손실 함수이고, **범주 교차 엔트로피(categorical cross-entropy)** 는 다중 클래스 분류에 대한 손실 함수입니다. torch.nn 모듈에서 범주형 교차점 손실은 실측값 레이블을 정수로 받아들임(예: y=2, 3개 클래스 중 0, 1, 2).

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.9. Two examples of loss functions in PyTorche
</figcaption>


* 위 그림은 두 경우 모두를 처리하기 위해 torch.nn에서 사용할 수 있는 두 가지 손실 함수, 즉 이진 분류와 정수 레이블이 있는 다중 클래스를 설명함. 이 두 손실 함수 각각은 로짓 또는 클래스 멤버쉽 확률의 형태로 예측을 수신하는 옵션도 가지고 있음.

#### The multilayer CNN architecture

* 구현하고자 하는 네트워크의 아키텍처는 아래 그림에 나와 있음. 입력은 28x28 그레이스케일 영상임. 채널 수(그레이스케일 이미지의 경우 1)와 입력 이미지 배치를 고려하면 입력 텐서의 치수는 배치 크기×28×28×1임. 입력 데이터는 커널 크기가 5x5인 두 개의 컨볼루션 레이어를 거침. 첫 번째 컨볼루션에는 32개의 출력 피쳐 맵이 있고, 두 번째 컨볼루션에는 64개의 출력 피쳐 맵이 있음. 각각의 컨볼루션 층은 최대 풀링 동작 P2×2의 형태로 서브 샘플링 층에 따르며 그런 다음 완전히 연결된 계층은 출력을 두 번째 완전히 연결된 계층으로 전달하며, 이 계층은 최종 소프트맥스 출력 계층으로 작동함. 우리가 구현하고자 하는 네트워크의 아키텍처는 아래 그림에 나와있음.

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.10. A deep CNN
</figcaption>

* 각 층의 텐서 치수는 다음과 같음.

* • Input: [batchsize×28×28×1]
* • Conv_1: [batchsize×28×28×32]
* • Pooling_1: [batchsize×14×14×32]
* • Conv_2: [batchsize×14×14×64]
* • Pooling_2: [batchsize×7×7×64]
* • FC_1: [batchsize×1024]
* • FC_2 and softmax layer: [batchsize×10]

* 컨볼루션 커널의 경우 입력 치수가 결과 특성 맵에 보존되도록 스트라이드=1을 사용하고 있음. 풀링 레이어의 경우 kernel_size=2를 사용하여 이미지를 하위 샘플링하고 출력 특성 맵의 크기를 축소함. 



