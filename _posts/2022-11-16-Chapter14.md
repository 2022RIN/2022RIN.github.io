---
layout: single
title:  "Chapter14. Classifying Images with Deep Convolutional Neural Networkss"
use_math: true
---

#### Topic
* 이 장에서는 이미지 분류를 위한 **컨벌루션 신경망(convolutional neural networks, CNNs)** 에 대한 내용임.
* 상향식 접근법(bottom-up-approach)을 사용하여 CNN의 기본 구성 요소에 대해 논의하는 것을 시작으로 CNN의 아키텍처에 대해 더 자세히 알아보고 파이토치에서 CNN을 구현하는 방법에 대해 알아봄. 
* 다음과 같은 항목을 다룸.
* 1) 1차원 및 2차원에서의 컨벌루션 연산
* 2) CNN 아키텍처의 구성 요소
* 3) 파이토치에서 심층 CNN 구현 
* 4) 일반화 성능 향상을 위한 데이터 확대 기법(data augmentation techiques)
* 5) 웃고있는 여부를 인식하기 위한 CNN 얼굴 분류기 구현 

## 1. Understanding CNNs and feature hierarchies: CNN 및 기능 계층 이해

* **중요한(관련) 특징(salient (relevant) features)** 을 성공적으로 추출하는 것은 모든 머신 러닝 알고리즘의 핵심 성능임. 전통적인 머신러닝 모델은 도메인 전문가가 제공하거나 계산 특징 추출 기술은 기반으로하는 입력 특징에 의존함. 이러한 이유로 CNN 레이어를 **특성 추출기**로 간주하는 것이 일반적임.
* 초기 레이어(입력 레이어 바로 뒤의 레이어)는 원시 데이터에서 낮은 수준의 특성을 추출하고, 후기 레이어(MLP처럼 완전 연결된 레이어)는 이러한 특성을 사용하여 연속적인 목표 값 또는 클래스 레이블을 예측함.
* 특성 유형의 다층 NN, 특히 심층 CNN은 **낮은 수준의 기능을 계층별 방식으로 결합하여 높은 수준의 특성을 형성함으로써 소위 특성 계층(feature hierarchy)을 구성함.** 
* 예를 들어, 이미지를 다루는 경우에 가장자리와 블롭과 같은 낮은 수준의 특성가 이전 레이어에서 추출되고, 이는 결합되어 높은 수준의 특성을 형성함. 
* 이와 같은 높은 수준의 특성은 건물이나 동물 같은 물체의 윤곽과 같은 복잡한 모양을 형성할 수 있음.


<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.1. Creating feature maps from an image (photo by Alexander Dummer on Unsplash)
</figcaption>

* 위 그림처럼 CNN은 입력 이미지에서 특성 맵을 계산함. 여기서 각 요소는 입력 이미지 픽셀의 로컬 패치에서 나옴.
* 이러한 픽셀들의 로컬 패치를 로컬 수용 필드(local receptive field)라함. CNN은 일반적으로 이미지 관련 작업에서 잘 수행되며 이는 다음과 같은 두 가지 아이디어 때문임.
* **희소 연결(sparse connectivity)**: 특성 맵의 단일 요소는 작은 픽셀 패치에만 연결된다(MLP의 경우와 같이 전체 입력 이미지에 연결하는 것과는 매우 다르다).
* **매개 변수 공유(parameter sharing)**: 입력 이미지의 다른 패치에 동일한 가중치가 사용됨.
* 위 두 아이디어의 결과로, 완전히 연결된 기존의 MLP를 컨볼루션 레이어로 대체하면 네트워크의 가중치(파라미터) 수가 상당히 감소하며, 두드러진 특성을 포착하는 능력이 향상됨.
* 이미지 데이터의 맥락에서, 가까운 거리의 픽셀들은 일반적으로 서로 멀리 떨어져 있는 픽셀들보다 서로에게 더 관련이 있다고 가정하는 것이 타당함.
* 일반적으로 **CNN은 끝에 하나 이상의 완전히 연결된 계층이 이어지는 여러 컨볼루션 및 하위 샘플링 계층으로 구성**됨. 완전히 연결된 층은 기본적으로 MLP이며, 여기서 모든 입력 단위 i는 가중치 $w_{ij}$로 모든 출력 단위 j에 연결됨.
* 일반적으로 **풀링 레이어(pooling layers)** 로 알려진 하위 샘플링 레이어에는 학습 가능한 매개 변수가 없음. 예를 들어 풀링 레이어에는 가중치 또는 편향 단위가 없지만 컨볼루션 레이어와 완전히 연결된 레이어 모두 훈련 중에 최적화된 가중치와 편향이 존재함.

## 2. Understanding CNNs and feature hierarchies: 이산 컨볼루션 수행

* 이산 컨볼루션(discrete convolution (or simply convolution))은 CNN의 기본 연산으로 어떻게 작동하는지 이해하는 것이 중요함. 

#### Discrete convolutions in one dimension: 1차원에서의 이산 컨볼루션

* 몇 가지 기본적 정의와 표기법을 살펴봄. $y=xw$ 두 벡터, x와 w에 대한 이산 컨볼루션은 벡터 x가 입력(또는 신호)이고, w는 필터 또는 커널임.
먼저 사용할 몇 가지 기본적인 정의와 표기법부터 살펴보겠습니다. 두 벡터, 즉 x와 w에 대한 이산 컨볼루션은 벡터 x가 우리의 입력(때로는 신호라고 불림)이고 w는 필터 또는 커널이라고 한다. 이산 컨볼루션은 수학적으로 다음과 같이 정의된다.

(1)

* 대괄호 [ ]는 벡터 요소의 인덱싱을 나타내는 데 사용되며 인덱스 i는 출력 벡터 y의 각 요소를 통과함.
* 앞의 공식에서 명확히 알아야할 것: $-\infty$ 에서 $\infty$와 x에 대한 음수 인덱스
* 합이 $-\infty$ 에서 $\infty$ 까지의 인덱스를 통과하는 것은 주로 기계 학습 애플리케이션에서 항상 유한한 특성 벡터를 다루기 때문임. 이에 따라 앞의 공식에 나타난 덧셈을 정확히 계산하기 위해 x와 w는 0으로 채워졌다고 가정함. 이를통해 출력 벡터 y가 무한한 크기를 가지며 0을 많이 포함함. x는 유한한 수의 0으로만 패딩이 됨. 

* 이와 같은 프로세스를 제로 패딩(zero-padding)또는 심플 패딩(simply padding)이라함. 
* 각 면에 패딩된 0의 수는 p로 표시되며 1차원 벡터 z의 패딩 예시는 아래와 같음. 

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.2. An example of padding
</figcaption>

* 원래 입력 x와 필터 w가 각각 n개와 m개의 원소를 가지고 있다고 가정함. 패딩 벡터 $x^{p}$는 n+2p의 크기를 가짐. 이산 컨볼루션을 계산하기 위한 실제 공식은 다음과 같이 변경됨.  

(2)

* 무한 지수 문제 해결 후 두 번째 문제는 x를 $i+m-k$로 인덱싱 하는 것임. 여기서 주목해야 할 중요점은 이 합계에서 x와 w가 서로 다른 방향으로 지수화 되었다는 것임. 
* 하나의 지수가 역방향으로 가는 합을 계산하는 것은 두 지수 중 하나인 x 또는 w가 패딩된 후에 그것들 중 하나를 뒤집은 후 전진 방향으로 합을 계산하는 것과 같음.
* 위와 같이 필터 w를 뒤집어 회전된 필터 $w^{r}$을 구한다고 가정, 그 다음 점적수(dot product) $x[i:i+m].w^{r}$를 구함. 여기서 $x[i:i+m]$는 크기가 m인 x의 패치임. 해당 작업은 슬라이딩 윈도우 방식처럼 반복되어 모든 출력 요소를 가져옴. 

* 다음 그림은 $x=[3 2 1 7 1 2 5 4]$ 및 $w=[\frac{1}{2} \frac{3}{4} 1 \frac{1}{4}]$의 예를 제공하여 처음 3개의 출력 요소가 계산되도록함. 

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.3. The steps for computing a discrete convolution
</figcaption>

* 앞의 예제에서 패딩 크기가 0(p = 0)임을 알 수 있음.
* 회전된 필터 $w^{r}$은 이동할 때마다 두 개의 셀에 의해 이동되며 이 변화는 컨볼루션의 또 다른 초 매개변수인 보폭임. 이 예에서 스트라이드(stride)는 s = 2임. 스트라이드는 입력 벡터의 크기보다 작은 양수여야함.

#### Padding inputs to control the size of the output feature maps: 출력 피쳐 맵의 크기를 제어하는 입력 패딩

* 지금까지, 유한 크기의 출력 벡터를 계산하기 위해 컨볼루션에서 제로 패딩만을 사용하였음. 기술적으로 패딩은 어떤 $p \geq 0$에도 적용이 가능하며 $p$의 선택에 따라 경계 셀은 x의 중간에 위치한 셀과 다르게 취급될 수 있음.
* n=5, m=3인 예에서, $p=0, x[0]$는 하나의 출력요소(예: $y[0]$)를 계산하는 데만 사용되는 반면 $x[1]$은 두 개의 출력 요소 (예: $y[0]$ 및 $y[1]$)를 계산하는 데 사용됨.
* 따라서 x의 요소에 대한 이 다른 처리는 대부분의 계산에서 나타났기 때문에 중간 요소인 x[2]에 인위적으로 더 중점을 둘 수 있다는 것을 알 수 있음.
* p = 2를 선택하면 이 문제를 피할 수 있으며, 이 경우 x의 각 요소는 y의 세 가지 요소를 계산하는 데 포함
* 또한 출력 y의 크기는 우리가 사용하는 패딩 전략의 선택에 따라 달라짐. 실제로 일반적으로 사용되는 패딩에는 풀, 동일, 유효의 세 가지 모드가 있음. 
* 풀 모드에서 패딩 매개변수 $p$는 $p = m – 1$로 설정되며 풀 패딩은 출력의 치수를 증가시킴. 따라서 CNN 아키텍처에는 거의 사용되지 않음. 이 경우 입력 크기 및 출력 크기가 동일해야 하는 요구 사항과 함께 패딩 파라미터 p가 필터 크기에 따라 계산됨.
* 마지막으로, 유효 모드에서 컨볼루션을 계산하는 것은 p = 0 (패딩 없음)인 경우를 의미함.
* 커널 크가 3X3이고 스트라이트가 1인 간단한 5X5 픽셀 입력을 위한 세 가지 다른 패딩 모드를 보여줌.

<figcaption style="text-align:center; font-size:15px; color:#808080">
Fig.4. The three modes of padding
</figcaption>

* CNN에서 가장 일반적으로 사용되는 패딩 모드는 동일한 패딩임. 다른 패딩 모드에 비해 장점 중 하나는 동일한 패딩이 벡터의 크기(또는 컴퓨터 비전에서 이미지 관련 작업을 할 때 입력 이미지의 높이와 너비)를 보존하여 네트워크 아키텍처를 보다 편리하게 설계할 수 있다는 것임.


#### Determining the size of the convolution output: 컨볼루션 출력의 크기 결정

* 컨볼루션의 출력 크기는 입력 벡터를 따라 필터 w를 이동하는 총 횟수에 의해 결정됨. 력 벡터의 크기가 n이고 필터의 크기가 m인 경우 패딩 p와 스트라이드를 사용하여 $y=xw$ 크기는 다음과 같이 결정됨. 

(3)

* 1차원에서 컨볼루션을 계산하는 방법을 배우기 위해 다음 코드 블록에 순진한 구현을 보여주고, 그 결과를 numpy.convolve 함수와 비교함. 코드는 다음과 같음. 














